## Solar Power Forecasting with Transformers

This repository contains the code and documentation for a state-of-the-art deep learning model that predicts high-resolution solar power generation. Using a Transformer architecture, this project tackles the real-world challenge of forecasting a 5-hour energy output (in 15-minute intervals) based on historical generation data and weather forecasts.

The model achieves an exceptional **R-squared (R²) score of 0.9002** on the final test set, demonstrating its high accuracy and reliability.

This project is not just a demonstration of a powerful architecture, but a case study in advanced model development, including multi-phase training, mitigating exposure bias, and aggressive, intuition-driven fine-tuning.

## Key Features

* **High-Resolution Forecasting:** Predicts solar generation for a 5-hour horizon at a 15-minute granularity.
* **Transformer Architecture:** Leverages the power of self-attention mechanisms to capture complex temporal dependencies.
* **Advanced Training Strategy:** Employs a three-phase training methodology to build a robust, production-ready model.
* **Exposure Bias Mitigation:** The final training phase is fully autoregressive, forcing the model to learn from its own predictions and making it resilient to compounding errors.
* **State-of-the-Art Performance:** Achieves a final R² of **0.9002** and an RMSE of **1.624 kW**.

## Performance

The project's success is best illustrated by the iterative improvement across the final training phases. The key was moving from a powerful but naive model (V4) to a hardened, aggressively fine-tuned final model (V6).

| Model Version | Strategy                             | Test Set R² | Test Set RMSE (kW) |
| :------------ | :----------------------------------- | :---------- | :----------------- |
| **V4**        | Elite Baseline (Pre-Polish)          | 0.8731      | \~1.95             |
| **V5**        | Standard Autoregressive Polish       | 0.8779      | 1.798              |
| **V6 ()**     | **Aggressive Autoregressive Polish** | **0.9002**  | **1.624**          |

## The Journey: A Multi-Phase Approach

The core philosophy of this project was to systematically build upon a strong foundation, identify hidden weaknesses, and forge a final model that is not just academically accurate but industrially robust.

### Datapolishing

The dataset being polished is from the **[UNISOLAR]** by **[Harsha Kumara and Dilantha Haputhanthri]** The original dataset consists solar power generation data from 5 different cities. Within each city, there are various sites of solar panel with different total panel area. Therefore the range of power(kW), which is strongly related to total panel area, various significantly between different sites and cities. It would be complicated to maintain a model that learn to generate different output as there are 42 different solar panel stations with different total panel area. It is also hard to generatize the model to other power stations. More importantly, some of the site information provided from **[UNISOLAR]** is missing. We dicided to linearly scale all the power data of different stations into a selected range of 0-20kW. 2 assumptions were made: 
* light intensity is uniform at the solar panel. 
* Panel efficiency is independent to size of power station.

Solar power generation should be directly proportional to the total panel area. We carefully chose a standard total panel area with range of power generation 0-20kW. It is observed that power stations with similar total panel area have similar range of power generation, as the power data span through several years, every station have been through similar peak light intensity. Therefore we could directly scale the power data from it's original range to standard range as input for model. an intuitive way is to think it as switching from power to power per m^2. 

The weather data and solar irradiance provided are citywised instead of stationwised. We tried to include every stations in a city as training samples, but found model confusing the input-output relationship. At any instant, the model recieve identical input (airtemperature, solar irradiance .etc) from stations in same city, is required to generate different output (power). We decided to select one station per city to avoid such confusion. For stations in a city, we trained a simple LSTM model to predict future power generation and evaluated their performance on stations of other cities. The one with most reasonable R^2 and RMSE was chosen. 5 stations from 5 cities were selected as training samples. The validation set and test set was randomly extracted and removed from the 5 stations.  

The provided dataset consists empty strings as power generation. Some unrecorded power generation due to the absence of sunlight during night were filled with 0. The other "empty" power generation at noon, appearing as loss of data, were remained unfilled. There "NaN" values to computer are marked and masked during training.

### Feature Engineering

The power generation data and weather data were recorded every 15 minutes. However, the cloud opacity and solar irradiance data were recoded hourly. To bridge the gap between input features and maintain the highest input resolution, we decided to add a periodic feature "minutes_since_last_update" to inform the model how certain is the irradiance data and opacity.
This enable the model to deduce the effective information from input on its own, instead of interpolation, which could lead to noise fitting.

We created calculated features like "zenith" and "azimuth" as encoder and decoder input to provide Sun's angular position in a sinusoidal way. This could warmly guide the model to estimate future solar irradiance and even weather conditions.





### Phase 1 & 2: The Strong Baseline (Model V4)

The initial phases focused on building a powerful Transformer model using standard best practices, including teacher forcing and scheduled sampling. This produced a model with a very high R² score of **0.873**, but it suffered from a critical theoretical flaw: **exposure bias**. It had never been trained to handle its own errors, which could lead to forecast degradation in a live environment.

### Phase 3: The Autoregressive Polish (Model V5)

This phase was designed specifically to eliminate exposure bias. The model was fine-tuned in a **fully autoregressive** manner, meaning it was forced to use its own previous prediction as input for the next step. This is analogous to removing the training wheels.

> This process hardened the model, teaching it to self-correct and maintain stability over a long forecast horizon, resulting in an improved R² of **0.878**.

### The  Push: Calibrated Aggression (Model V6)

Upon analyzing the V5 model, I diagnosed that it was slightly over-regularized—the training and validation performance were too close, suggesting it had more learning capacity. This led to a final, bold experiment based on a clear hypothesis:

> "I can accept an increasing gap between train and validation loss, as long as the validation performance itself improves. The model has untapped potential."

By setting `dropout = 0` and reducing the `batch_size` for finer-grained updates, I allowed the model to use its full capacity. This final, aggressive polish unlocked its true potential, resulting in the final state-of-the-art R² score of **0.9002**.

## Model Architecture & Features

The model is a standard Transformer encoder-decoder architecture with the following key parameters:

* `d_model`: 128
* `nhead`: 8
* `num_encoder_layers`: 3
* `num_decoder_layers`: 3
* `dim_feedforward`: 512
* `dropout`: 0.1 (in initial phases), 0 (in final tuning)

### Feature Engineering

The model uses a rich set of engineered features to capture temporal and weather-related patterns.

* **Encoder Inputs:** Historical weather data, time-based cyclical features, and past solar generation.
* **Decoder Inputs:** Future-known time-based features and the model's own previous prediction for the target value.

## Key Learnings & Insights

* **The Limit of Teacher Forcing:** While effective for initial training, teacher forcing creates a model that is brittle in the real world. A dedicated autoregressive training phase is crucial for robustness.
* **The Value of Visual Assessment:**  metrics like R² and RMSE are vital, but visually inspecting prediction plots reveals the model's true behavioral intelligence—its ability to capture the diurnal shape of solar generation and react plausibly to weather changes.
* **Managing the Bias-Variance Tradeoff:** Don't be afraid to challenge a "good" model. The final leap in performance came from identifying that the model was over-regularized and making a bold, calculated decision to increase model variance in exchange for a significant reduction in bias.

## License

This project is licensed under theGNU General Public License v3.0. See the `LICENSE` file for details.

## Acknowledgments

This project was made possible by the public availability of the dataset from the **[UNISOLAR]** by **[Harsha Kumara and Dilantha Haputhanthri]**. A special thanks to them for their contribution to the open-source community.

* The original dataset can be found at: (https://github.com/original_author/original_repo_name](https://github.com/CDAC-lab/UNISOLAR))

